{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.backend import set_session, get_session\n",
    " \n",
    "from keras import backend as K\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import model_from_json, Sequential, Model, load_model\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Lambda, ELU, Cropping2D, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model_for_dog_breed = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res_model_for_adjusting_shape = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')\n",
    "train_Resnet = bottleneck_features['train']\n",
    "valid_Resnet = bottleneck_features['valid']\n",
    "test_Resnet = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Resnet_Model = Sequential()\n",
    "Resnet_Model.add(GlobalAveragePooling2D(input_shape=train_Resnet.shape[1:]))\n",
    "Resnet_Model.add(Dense(133,activation='softmax'))\n",
    "Resnet_Model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "Resnet_Model.load_weights('saved_models/weights.best.Resnet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Resnet50(tensor):\n",
    "    return ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define generic function for pre-processing images into 4d tensor as input for CNN\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "#predicts the dog breed based on the pretrained ResNet50 models with weights from imagenet\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model_for_dog_breed.predict(img))\n",
    "\n",
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    print(prediction)\n",
    "    return ((prediction <= 268) & (prediction >= 151))\n",
    "\n",
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0\n",
    "\n",
    "def Resnet_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    y = path_to_tensor(img_path)\n",
    "    y = preprocess_input(y)\n",
    "    print(y.shape)\n",
    "    x = Res_model_for_adjusting_shape.predict(y)\n",
    "    #bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))\n",
    "    print(x.shape)\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = Resnet_Model.predict(x)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]\n",
    "\n",
    "\n",
    "def get_correct_prenom(word, vowels):\n",
    "    if word[0].lower() in vowels:\n",
    "            return \"an\"\n",
    "    else:\n",
    "        return \"a\"\n",
    "\n",
    "\n",
    "def predict_image(img_path):\n",
    "    vowels=[\"a\",\"e\",\"i\",\"o\",\"u\"]\n",
    "    #if a dog is detected in the image, return the predicted breed.\n",
    "    if dog_detector(img_path)==True:\n",
    "        predicted_breed=Resnet_predict_breed(img_path).rsplit('.',1)[1].replace(\"_\", \" \")\n",
    "        prenom=get_correct_prenom(predicted_breed,vowels)\n",
    "        return \"The predicted dog breed is \" + prenom + \" \"+ str(predicted_breed) + \".\"\n",
    "    #if a human is detected in the image, return the resembling dog breed.\n",
    "    if face_detector(img_path)==True:\n",
    "        predicted_breed=Resnet_predict_breed(img_path).rsplit('.',1)[1].replace(\"_\", \" \")\n",
    "        prenom=get_correct_prenom(predicted_breed,vowels)\n",
    "        return \"This photo looks like \" + prenom + \" \"+ str(predicted_breed) + \".\"\n",
    "    #if neither is detected in the image, provide output that indicates an error.\n",
    "    else:\n",
    "        return \"No human or dog could be detected, please provide another picture.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dog_names=[]\n",
    "with open('data/dog_names.json') as json_file:\n",
    "    dog_names = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='static/Brittany_02625.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "(1, 224, 224, 3)\n",
      "(1, 1, 1, 2048)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The predicted dog breed is a Brittany.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_image('static/Brittany_02625.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['builtins',\n",
       " 'builtins',\n",
       " 'keras.utils.np_utils',\n",
       " 'numpy',\n",
       " 'glob',\n",
       " 'keras.preprocessing.image',\n",
       " 'keras.backend',\n",
       " 'pickle',\n",
       " 'cv2',\n",
       " 'tensorflow',\n",
       " 'pandas',\n",
       " 'os',\n",
       " 'matplotlib.pyplot',\n",
       " 'json',\n",
       " 'types']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__\n",
    "list(imports())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to had\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm==4.11.2\n",
      "tensorflow==1.3.0\n",
      "pandas==0.23.3\n",
      "numpy==1.18.4\n",
      "matplotlib==2.1.0\n"
     ]
    }
   ],
   "source": [
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow==1.3.0\n",
    "numpy==1.12.1\n",
    "tqdm==4.11.2\n",
    "pandas==0.23.3\n",
    "matplotlib==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.3\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
